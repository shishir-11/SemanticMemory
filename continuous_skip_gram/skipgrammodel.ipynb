{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRu23aCNM27z",
        "outputId": "108dfb57-fc42-497e-c656-cddf5aa45b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from gensim.models import Word2Vec as w2v\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "PATH = 'input_text.txt'\n",
        "sw = stopwords.words('english')\n",
        "\n",
        "lines = []\n",
        "with open(PATH, 'r') as f:\n",
        "    for l in f:\n",
        "        lines.append(l)\n",
        "\n",
        "print(lines[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove new lines\n",
        "lines = [line.rstrip() for line in lines]\n",
        "\n",
        "# make all characters lower\n",
        "lines = [line.lower() for line in lines]\n",
        "\n",
        "# remove punctuations from each line\n",
        "lines = [line.translate(str.maketrans('', '', string.punctuation)) for line in lines]\n",
        "\n",
        "# tokenize\n",
        "lines = [word_tokenize(line) for line in lines]\n",
        "\n",
        "def remove_stopwords(lines, sw = sw):\n",
        "    res = []\n",
        "    for line in lines:\n",
        "        original = line\n",
        "        line = [w for w in line if w not in sw]\n",
        "        if len(line) < 1:\n",
        "            line = original\n",
        "        res.append(line)\n",
        "    return res\n",
        "\n",
        "filtered_lines = remove_stopwords(lines = lines, sw = sw)"
      ],
      "metadata": {
        "id": "ik5_h1RvOm8W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_folds = 10\n",
        "\n",
        "# Initialize KFold\n",
        "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize list to store results\n",
        "results = []\n",
        "\n",
        "# Loop over folds\n",
        "for train_index, test_index in kf.split(filtered_lines):\n",
        "    # Split data into train and test sets\n",
        "    train_data = [filtered_lines[i] for i in train_index]\n",
        "    test_data = [filtered_lines[i] for i in test_index]\n",
        "\n",
        "    # Train model on train data\n",
        "    w1 = w2v(\n",
        "        train_data,\n",
        "        min_count=3,\n",
        "        sg = 1,\n",
        "        window=7\n",
        "    )\n",
        "\n",
        "    # Evaluate model on test data\n",
        "    fold_results_1 = [r[0] for r in w1.wv.most_similar('moon')]\n",
        "    print(f\"Results for Train Set: {fold_results_1}\")\n",
        "    results.append(fold_results_1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO57WTK7Pj7x",
        "outputId": "a0d3a4d8-ec80-4f4d-9b2a-a3df44a32bf9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Train Set: ['variation', 'leads', 'interactions', 'eyes', 'unique', 'reactions', 'embryos', 'core', 'components', 'pure']\n",
            "Results for Train Set: ['skull', 'reactions', 'leads', 'components', 'skin', 'cure', 'mature', 'eyes', 'suggesting', 'chains']\n",
            "Results for Train Set: ['method', 'eyes', 'leads', 'object', 'distinguish', 'substrate', 'symbolic', 'variable', 'embryos', 'interpreted']\n",
            "Results for Train Set: ['leads', 'hidden', 'eyes', 'detail', 'skin', 'usually', 'interactions', 'attendants', 'variation', 'means']\n",
            "Results for Train Set: ['leads', 'eyes', 'substrate', 'useful', 'attendants', 'cure', 'interactions', 'skin', 'components', 'breast']\n",
            "Results for Train Set: ['variation', 'eyes', 'flesh', 'skin', 'leads', 'sequence', 'taste', 'object', 'pocket', 'mature']\n",
            "Results for Train Set: ['supernatural', 'detail', 'gives', 'therapy', 'difference', 'breaks', 'object', 'allows', 'looks', 'rather']\n",
            "Results for Train Set: ['variation', 'leads', 'hidden', 'eyes', 'attendants', 'embryos', 'rather', 'interactions', 'cure', 'resemble']\n",
            "Results for Train Set: ['variation', 'attendants', 'eyes', 'leads', 'requires', 'somewhat', 'synthesized', 'object', 'mixture', 'supernatural']\n",
            "Results for Train Set: ['variation', 'supernatural', 'variable', 'skin', 'eyes', 'mature', 'allows', 'skull', 'easily', 'method']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2 = w2v(\n",
        "        filtered_lines,\n",
        "        min_count=3,\n",
        "        sg = 1,\n",
        "        window=7\n",
        "    )\n",
        "\n",
        "# Evaluate model on test data\n",
        "fold_results_2 = [r[0] for r in w2.wv.most_similar('moon')]\n",
        "print(f\"The Actual Fold_results are {fold_results_2}\")\n",
        "error_sum = 0\n",
        "for i in results:\n",
        "  err = len(list(set(i) & set(fold_results_2)))/10\n",
        "  print(f\"Error for this set is {err}\")\n",
        "  error_sum += err\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buj9m8fqffEV",
        "outputId": "82d7e94a-8587-4c11-9787-bdded5e7837a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Actual Fold_results are ['leads', 'variation', 'attendants', 'detail', 'variable', 'might', 'riding', 'method', 'skull', 'object']\n",
            "Error for this set is 0.2\n",
            "Error for this set is 0.2\n",
            "Error for this set is 0.4\n",
            "Error for this set is 0.4\n",
            "Error for this set is 0.2\n",
            "Error for this set is 0.3\n",
            "Error for this set is 0.2\n",
            "Error for this set is 0.3\n",
            "Error for this set is 0.4\n",
            "Error for this set is 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print average result over all folds\n",
        "print(f\"The average error over the training sets : {error_sum/n_folds}\")\n",
        "\n",
        "emb_df = (\n",
        "    pd.DataFrame(\n",
        "        [w2.wv.get_vector(str(n)) for n in w2.wv.key_to_index],\n",
        "        index = w2.wv.key_to_index\n",
        "    )\n",
        ")\n",
        "print(emb_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRQvb6QmfdWI",
        "outputId": "20e73fa8-cd9d-4dfd-9ebb-d0b7b9c4888f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average error over the training sets : 0.3\n",
            "(16323, 100)\n"
          ]
        }
      ]
    }
  ]
}